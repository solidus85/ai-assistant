# AI Assistant Configuration
# Copy this file to .env and adjust the values as needed

# Flask settings
HOST=127.0.0.1
PORT=5000
DEBUG=False
SECRET_KEY=your-secret-key-here-change-in-production

# Ollama settings
OLLAMA_BASE_URL=http://localhost:11434
MODEL_NAME=gemma3:12b-it-qat
EXTRACTION_MODEL=phi3

# Database paths - can be absolute or relative
# Relative paths are relative to the project root
DATABASE_PATH=./data/work_assistant.db
CHROMA_PERSIST_DIRECTORY=./data/chroma_db

# Alternative path configurations:
# For Docker volumes:
# DATABASE_PATH=/app/data/work_assistant.db
# CHROMA_PERSIST_DIRECTORY=/app/data/chroma_db

# For system-wide installation:
# DATABASE_PATH=/var/lib/ai-assistant/work_assistant.db
# CHROMA_PERSIST_DIRECTORY=/var/lib/ai-assistant/chroma_db

# For user-specific data:
# DATABASE_PATH=~/.ai-assistant/work_assistant.db
# CHROMA_PERSIST_DIRECTORY=~/.ai-assistant/chroma_db

# Model settings (optimized for RTX 4080)
MAX_TOKENS=2048
TEMPERATURE=0.7
NUM_CTX=4096
NUM_BATCH=512
NUM_THREAD=16
TOP_K=40
TOP_P=0.9
REPEAT_PENALTY=1.1

# GPU settings
NUM_GPU=99
GPU_LAYERS=99

# Work assistant settings
MAX_SEARCH_RESULTS=10
DELIVERABLE_WARNING_DAYS=7
MAX_CONVERSATION_HISTORY=10

# Logging
LOG_LEVEL=INFO
# LOG_FILE=/var/log/ai-assistant.log