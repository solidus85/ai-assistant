services:
  web:
    build: .
    container_name: ai-assistant
    ports:
      - "5000:5000"
    environment:
      - HOST=0.0.0.0
      - PORT=5000
      - DEBUG=False
      # Use host.docker.internal to connect to Ollama running on Windows host
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      # Database paths inside container
      - DATABASE_PATH=/app/data/work_assistant.db
      - CHROMA_PERSIST_DIRECTORY=/app/data/chroma_db
    env_file:
      - .env
    volumes:
      # Mount data directory for persistent storage
      - ./data:/app/data
      # Mount secret key directory
      - ./.secret_key:/app/.secret_key
      # For development: mount source code for hot-reload (optional)
      # - ./src:/app/src
      # - ./config.py:/app/config.py
      # - ./run.py:/app/run.py
    restart: unless-stopped
    extra_hosts:
      # Ensures host.docker.internal works on Linux hosts too
      - "host.docker.internal:host-gateway"