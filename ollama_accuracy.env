# Optimal Accuracy Configuration
CUDA_VISIBLE_DEVICES=0
OLLAMA_NUM_GPU=-1              # Auto-detect optimal GPU layers
OLLAMA_CUDA=1

# Memory for accuracy priority
OLLAMA_MAX_LOADED_MODELS=1
OLLAMA_MEMORY_LIMIT=58G        # Use most available RAM
OLLAMA_GPU_OVERHEAD=1073741824 # 1GB overhead for safety

# Quality-focused settings
OLLAMA_FLASH_ATTENTION=1
OLLAMA_USE_MMAP=1
OLLAMA_USE_MLOCK=1
OLLAMA_F16_KV=true             # Use FP16 for KV cache (better quality)

# Inference settings
OLLAMA_NUM_PARALLEL=1          # Single stream for consistency
OLLAMA_COMPUTE_TYPE=float16    # Higher precision computation
